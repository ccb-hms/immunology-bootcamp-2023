---
title: "Session 2: Functions and Data Wrangling"
author: ""
format: 
  html: default
code-annotations: select
---

## Functions and their arguments

### What are functions?

A key feature of R is functions. Functions are **"self contained" modules of code that accomplish a specific task**. Functions usually take in some sort of data structure (value, vector, dataframe etc.), process it, and return a result.

The general usage for a function is the name of the function followed by parentheses:

``` r
function_name(input)
```

The input(s) are called **arguments**, which can include:

1.  the physical object (any data structure) on which the function carries out a task
2.  specifications that alter the way the function operates (e.g. options)

Not all functions take arguments, for example:

``` r
getwd()
```

However, most functions can take several arguments. If you don't specify a required argument when calling the function, you will either receive an error or the function will fall back on using a *default*.

The **defaults** represent standard values that the author of the function specified as being "good enough in standard cases". An example would be what symbol to use in a plot. However, if you want something specific, simply change the argument yourself with a value of your choice.

### Basic functions

We have already used a few examples of basic functions in the previous lessons i.e `getwd()`, `c()`, and `factor()`. These functions are available as part of R's built in capabilities, and we will explore a few more of these base functions below.

Let's revisit a function that we have used previously to combine data `c()` into vectors. The *arguments* it takes is a collection of numbers, characters or strings (separated by a comma). The `c()` function performs the task of combining the numbers or characters into a single vector. You can also use the function to add elements to an existing vector:

```{r}
glengths <- c(4.6, 3000, 50000)
glengths <- c(glengths, 90) # adding at the end 
glengths <- c(30, glengths) # adding at the beginning
```

What happens here is that we take the original vector `glengths` (containing three elements), and we are adding another item to either end. We can do this over and over again to build a vector or a dataset.

Since R is used for statistical computing, many of the base functions involve mathematical operations. One example would be the function `sqrt()`. The input/argument must be a number, and the output is the square root of that number. Let's try finding the square root of 81:

```{r}
sqrt(81)
```

Now what would happen if we **called the function** (e.g. ran the function), on a *vector of values* instead of a single value?

```{r}
sqrt(glengths)
```

In this case the task was performed on each individual value of the vector `glengths` and the respective results were displayed.

Let's try another function, this time using one that we can change some of the *options* (arguments that change the behavior of the function), for example `round`:

```{r}
round(3.14159)
```

We can see that we get `3`. That's because the default is to round to the nearest whole number. **What if we want a different number of significant digits?** Let's first learn how to find available arguments for a function.

### Seeking help on arguments for functions

The best way of finding out this information is to use the `?` followed by the name of the function. Doing this will open up the help manual in the bottom right panel of RStudio that will provide a description of the function, usage, arguments, details, and examples:

``` r
?round
```

Alternatively, if you are familiar with the function but just need to remind yourself of the names of the arguments, you can use:

```{r}
args(round)
```

Even more useful is the `example()` function. This will allow you to run the examples section from the Online Help to see exactly how it works when executing the commands. Let's try that for `round()`:

```{r}
example("round")
```

In our example, we can change the number of digits returned by **adding an argument**. We can type `digits=2` or however many we may want:

```{r}
round(3.14159, digits=2)
```

> *NOTE:* If you provide the arguments in the exact same order as they are defined (in the help manual) you don't have to name them:
>
> round(3.14159, 2)
>
> However, it's usually not recommended practice because it involves a lot of memorization. In addition, it makes your code difficult to read for your future self and others, especially if your code includes functions that are not commonly used. (It's however OK to not include the names of the arguments for basic functions like `mean`, `min`, etc...). Another advantage of naming arguments, is that the order doesn't matter. This is useful when a function has many arguments.

**Exercise**

::: {.callout-note appearance="simple" icon="false"}
## Basic

1.  Let's use base R function to calculate **mean** value of the `glengths` vector. You might need to search online to find what function can perform this task.
2.  Create a new vector `test <- c(1, NA, 2, 3, NA, 4)`. Use the same base R function from exercise 1 (with addition of proper argument), and calculate mean value of the `test` vector. The output should be `2.5`. \> *NOTE:* In R, missing values are represented by the symbol `NA` (not available). It's a way to make sure that users know they have missing data, and make a conscious decision on how to deal with it. There are ways to ignore `NA` during statistical calculation, or to remove `NA` from the vector. If you want more information related to missing data or `NA` you can [go to this page](https://stats.oarc.ucla.edu/r/faq/how-does-r-handle-missing-values/) (please note that there are many advanced concepts on that page that have not been covered in class).
3.  Another commonly used base function is `sort()`. Use this function to sort the `glengths` vector in **descending** order.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution

```{r}
# Setup
glengths <- c(4.6, 3000, 50000)
glengths <- c(glengths, 90) # adding at the end 
glengths <- c(30, glengths) # adding at the beginning

# Basic 
# 1
mean(glengths)
# 2
test <- c(1, NA, 2, 3, NA, 4)
mean(test, na.rm=TRUE)
# 3
sort(glengths, decreasing = TRUE)
```
:::

::: {.callout-caution appearance="simple" icon="false"}
## Advanced

1.  Use `rnorm` and the `matrix` functions to create a random square matrix with $6$ rows/columns.
2.  Calculate the mean of each *row* in the matrix, so you should have 6 means total.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution
```{r}

# We need to sample a length 36 vector, then coerce it into a matrix
my_matrix <- matrix(rnorm(36), nrow=6)

# There's a built-in function called rowMeans! It's always good to look things up. 
rowMeans(my_matrix)

# We could also use apply to call mean on each row of the matrix
apply(my_matrix, 1, mean)
```
:::

::: {.callout-important appearance="simple" icon="false"}
## Challenge

1.  Create vector `c_data <- c(1, NA, 2, 3, NA, 4, 4, 3, 2, NA, NA, 2, 4, 2, 3, 4, 4, 2, 1, NA, 1, 1, 1)`. Fill in the NA values with the mean of all non-missing values.

2.  Re-create the vector with its `NA`s. Instead of filling in the missing data with the mean, estimate the parameter of a Poisson distribution from the data and sample from it to fill in the missing data.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution
```{r}
# 1
c_data <- c(1, NA, 2, 3, NA, 4, 4, 3, 2, NA, NA, 2, 4, 2, 3, 4, 4, 2, 1, NA, 1, 1, 1)
c_data[is.na(c_data)] <- mean(c_data, na.rm = TRUE)

# 2
c_data <- c(1, NA, 2, 3, NA, 4, 4, 3, 2, NA, NA, 2, 4, 2, 3, 4, 4, 2, 1, NA, 1, 1, 1)

# We need this to calculate how many numbers we need to sample
num_na <- sum(is.na(c_data)) 
# A poisson distribution is paramaterized by it's mean. 
# so we just need the mean of the data to model
new_vals <- rpois(num_na, mean(c_data, na.rm = TRUE))
# And finally, we can index the data to set the sampled values equal to it
c_data[is.na(c_data)] <- new_vals
```
:::

------------------------------------------------------------------------

### User-defined Functions

One of the great strengths of R is the user's ability to add functions. Sometimes there is a small task (or series of tasks) you need done and you find yourself having to repeat it multiple times. In these types of situations, it can be helpful to create your own custom function. The **structure of a function is given below**:

``` r
name_of_function <- function(argument1, argument2) {
    statements or code that does something
    return(something)
}
```

-   First you give your function a name.
-   Then you assign value to it, where the value is the function.

When **defining the function** you will want to provide the **list of arguments required** (inputs and/or options to modify behaviour of the function), and wrapped between curly brackets place the **tasks that are being executed on/using those arguments**. The argument(s) can be any type of object (like a scalar, a matrix, a dataframe, a vector, a logical, etc), and it's not necessary to define what it is in any way.

Finally, you can **"return" the value of the object from the function**, meaning pass the value of it into the global environment. The important idea behind functions is that objects that are created within the function are local to the environment of the function -- they don't exist outside of the function.

Let's try creating a simple example function. This function will take in a numeric value as input, and return the squared value.

```{r}
square_it <- function(x) {
    square <- x * x
    return(square)
}
```

Once you run the code, you should see a function named `square_it` in the Environment panel (located at the top right of Rstudio interface). Now, we can use this function as any other base R functions. We type out the name of the function, and inside the parentheses we provide a numeric value `x`:

```{r}
square_it(5)
```

Pretty simple, right? In this case, we only had one line of code that was run, but in theory you could have many lines of code to get obtain the final results that you want to "return" to the user.

> #### Do I always have to `return()` something at the end of the function?
>
> In the example above, we created a new variable called `square` inside the function, and then return the value of `square`. If you don't use `return()`, by default R will return the value of the last line of code inside that function. That is to say, the following function will also work.
>
> ```{r}
> square_it <- function(x) {
>    x * x
> }
> ```
>
> However, we **recommend** always using `return` at the end of a function as the best practice.

We have only scratched the surface here when it comes to creating functions! We will revisit this in later lessons, but if interested you can also find more detailed information on this [R-bloggers site](https://www.r-bloggers.com/how-to-write-and-debug-an-r-function/), which is where we adapted this example from.

**Exercise**

::: {.callout-note appearance="simple" icon="false"}
## Basic

1.  Let's create a function `temp_conv()`, which converts the temperature in Fahrenheit (input) to the temperature in Kelvin (output).
    -   We could perform a two-step calculation: first convert from Fahrenheit to Celsius, and then convert from Celsius to Kelvin.
    -   The formula for these two calculations are as follows: temp_c = (temp_f - 32) \* 5 / 9; temp_k = temp_c + 273.15. To test your function,
    -   if your input is 70, the result of `temp_conv(70)` should be 294.2611.
2.  Now we want to round the temperature in Kelvin (output of `temp_conv()`) to a single decimal place. Use the `round()` function with the newly-created `temp_conv()` function to achieve this in one line of code. If your input is 70, the output should now be 294.3.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution

```{r}
# Basic

# 1
temp_conv <- function(temp_f) {
  temp_c = (temp_f - 32) * 5 / 9
  temp_k = temp_c + 273.15
  return (temp_k)
}

# 2
round(temp_conv(70), digits = 1)
```
:::


::: {.callout-caution appearance="simple" icon="false"}
## Advanced

The Fibonacci sequence is $0, 1, 1, 2, 3, 5, 8, ...$ where the first two terms are 0 and 1, and for all other terms $n^{th}$ term is the sum of the $(n-1)^{th}$ and $(n-2)^{th}$ terms. Note that for `n=0` you should return 0 and for `n=1` you should return 1 as the first 2 terms. 

1.  Write a function `fibonacci` which takes in a single integer argument `n` and returns the $n^{th}$ term in the Fibonacci sequence.

2.  Have your function `stop` with an appropriate message if the argument `n` is not an integer. [Stop](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/stop) allows you to create your own errors in R. [This StackOverflow thread](https://stackoverflow.com/questions/3476782/check-if-the-number-is-integer) contains useful information on how to tell if something is or is not an integer in R.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution

```{r}
# Advanced
fibonacci <- function(n){
  
  # These next 3 lines are part 2
  if((n %% 1)!=0){
    stop("Must provide an integer to fibonacci")
  }
  fibs <- c(0,1)
  for (i in 2:n){
    fibs <- c(fibs, fibs[i-1]+fibs[i])
  }
  return(fibs[n+1])
}
```
:::


::: {.callout-important appearance="simple" icon="false"}
## Challenge

Re-write your `fibonacci` function so that it calculates the Fibonacci sequence *recursively*, meaning that it calls itself. Your function should contain no loops or iterative code.

You will need to define two *base cases*, where the function does not call itself.
:::

::: {.callout-tip icon="false" collapse="true"}
## Solution

```{r}
#Challenge
fibonacci2 <- function(n){
  if((n %% 1)!=0){
    stop("Must provide an integer to fibonacci")
  }
  # We call these two if statement the 'base cases' of the recursion
  if (n==0){
    return(0)
  }
  if (n==1){
    return(1)
  }
  # And this is the recursive case, where the function calls itself
  return(fibonacci2(n-1)+fibonacci2(n-2))
}
```
Recursion isn't relevant to most data analysis, as it is often significantly slower than a non-recursive solution in most programming languages. 

However, setting up a solution as recursive sometimes allows us to perform an algorithmic strategy called [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) and is fundamental to most [sequence alignment algorithms](https://open.oregonstate.education/appliedbioinformatics/chapter/chapter-3/).
:::

## For Loops


Loops are a fundamental structure for repetition in programming.
`for` loops perform the same action for each item in a list of things.
The basic syntax is:

```{r}
#| eval: false
for (item in list_of_items) {
  do_something(item)
}
```

We can create a vector on the fly to loop a particular number of times:

```{r}
for (i in 1:5){
  print(i)
}
```

Or use a pre-existing vector or list. 

```{r}
volumes = c(1.6, 3, 8)
for (volume in volumes){
  mass <- 2.65 * volume ^ 0.9
  print(mass)
}
```

We also might want to loop over indices so we can access multiple vectors. 

```{r}
as <- c(2.65, 1.28, 3.29)
bs <- c(0.9, 1.1, 1.2)
volumes = c(1.6, 3, 8)
masses <- vector(mode="numeric", length=length(volumes))
for (i in 1:length(volumes)){
   mass <- as[i] * volumes[i] ^ bs[i]
   masses[i] <- mass
}
masses
```

We can use functions inside loops. For example, let’s take a function that returns an estimated mass if the `volume > 5` and `NA` if it’s not.

```{r}
est_mass <- function(volume, a, b){
  if (volume > 5) {
    mass <- a * volume ^ b
  } else {
    mass <- NA
  }
  return(mass)
}
```

We can then call the function to populate a vector item by item. 

```{r}
masses <- vector(mode="numeric", length=length(volumes))
for (i in 1:length(volumes)){
   mass <- est_mass(volumes[i], as[i], bs[i])
   masses[i] <- mass
}
masses
```

To note, this is the for loop equivalent of an `mapply` statement.

```{r}
masses_apply <- mapply(est_mass, volumes, as, bs)
masses_apply
```
In R we often want to use `apply` statements as opposed to explicitly writing loops. 

## Data manipulation using **`dplyr`** and **`tidyr`**

Bracket subsetting is handy, but it can be cumbersome and difficult to
read, especially for complicated operations.

Some packages can greatly facilitate our task when we manipulate data.
Packages in R are basically sets of additional functions that let you
do more stuff. The functions we've been using so far, like `str()` or
`data.frame()`, come built into R; Loading packages can give you access to other
specific functions. Before you use a package for the first time you need to install
it on your machine, and then you should import it in every subsequent
R session when you need it.

- The package **`dplyr`** provides powerful tools for data manipulation tasks.
  It is built to work directly with data frames, with many manipulation tasks
  optimised.

- As we will see latter on, sometimes we want a data frame to be reshaped to be able
  to do some specific analyses or for visualisation. The package **`tidyr`** addresses
  this common problem of reshaping data and provides tools for manipulating
  data in a tidy way.

To learn more about **`dplyr`** and **`tidyr`** after the workshop,
you may want to check out this [handy data transformation with
**`dplyr`**
cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf)
and this [one about
**`tidyr`**](https://raw.githubusercontent.com/rstudio/cheatsheets/main/tidyr.pdf).

- The **`tidyverse`** package is an "umbrella-package" that installs
  several useful packages for data analysis which work well together,
  such as **`tidyr`**, **`dplyr`**, **`ggplot2`**, **`tibble`**, etc.
  These packages help us to work and interact with the data.
  They allow us to do many things with your data, such as subsetting, transforming,
  visualising, etc.

If you did the set up, you should have already installed the tidyverse package.
Check to see if you have it by trying to load in from the library:

```{r, message=FALSE, purl=TRUE}
## load the tidyverse packages, incl. dplyr
library("tidyverse")
```

If you got an error message `there is no package called ‘tidyverse’` then you have not
installed the package yet for this version of R. To install the **`tidyverse`** package type:

```{r, eval=FALSE, purl=TRUE}
BiocManager::install("tidyverse")
```

If you had to install the **`tidyverse`** package, do not forget to load it in this R session by using the `library()` command above!


## Loading data with tidyverse

Instead of `read.csv()`, we will read in our data using the `read_csv()`
function (notice the `_` instead of the `.`), from the tidyverse package
**`readr`**.

```{r, message=FALSE, purl=TRUE}
rna <- read_csv("data/rnaseq.csv")

## view the data
rna
```

Notice that the class of the data is now referred to as a "tibble".

Tibbles tweak some of the behaviors of the data frame objects we introduced in the
previously. The data structure is very similar to a data frame. For our purposes
the only differences are that:

1. It displays the data type of each column under its name.
  Note that \<`dbl`\> is a data type defined to hold numeric values with
  decimal points.

2. It only prints the first few rows of data and only as many columns as fit on
  one screen.

We are now going to learn some of the most common **`dplyr`** functions:

- `select()`: subset columns
- `filter()`: subset rows on conditions
- `mutate()`: create new columns by using information from other columns
- `group_by()` and `summarise()`: create summary statistics on grouped data
- `arrange()`: sort results
- `count()`: count discrete values

## Selecting columns and filtering rows

To select columns of a data frame, use `select()`. The first argument
to this function is the data frame (`rna`), and the subsequent
arguments are the columns to keep.

```{r, purl=TRUE}
select(rna, gene, sample, tissue, expression)
```

To select all columns *except* certain ones, put a "-" in front of
the variable to exclude it.

```{r, purl=TRUE}
select(rna, -tissue, -organism)
```

This will select all the variables in `rna` except `tissue`
and `organism`.

To choose rows based on a specific criteria, use `filter()`:

```{r, purl=TRUE}
filter(rna, sex == "Male")
filter(rna, sex == "Male" & infection == "NonInfected")
```

Now let's imagine we are interested in the human homologs of the mouse
genes analysed in this dataset. This information can be found in the
last column of the `rna` tibble, named
`hsapiens_homolog_associated_gene_name`.  To visualise it easily, we
will create a new table containing just the 2 columns `gene` and
`hsapiens_homolog_associated_gene_name`.

```{r}
genes <- select(rna, gene, hsapiens_homolog_associated_gene_name)
genes
```

Some mouse genes have no human homologs. These can be retrieved using
`filter()` and the `is.na()` function, that determines whether
something is an `NA`.

```{r, purl=TRUE}
filter(genes, is.na(hsapiens_homolog_associated_gene_name))
```

If we want to keep only mouse genes that have a human homolog, we can
insert a "!" symbol that negates the result, so we're asking for
every row where hsapiens\_homolog\_associated\_gene\_name *is not* an
`NA`.

```{r, purl=TRUE}
filter(genes, !is.na(hsapiens_homolog_associated_gene_name))
```

## Pipes

What if you want to select and filter at the same time? There are three
ways to do this: use intermediate steps, nested functions, or pipes.

With intermediate steps, you create a temporary data frame and use
that as input to the next function, like this:

```{r, purl=TRUE}
rna2 <- filter(rna, sex == "Male")
rna3 <- select(rna2, gene, sample, tissue, expression)
rna3
```

This is readable, but can clutter up your workspace with lots of
intermediate objects that you have to name individually. With multiple
steps, that can be hard to keep track of.

You can also nest functions (i.e. one function inside of another),
like this:

```{r, purl=TRUE}
rna3 <- select(filter(rna, sex == "Male"), gene, sample, tissue, expression)
rna3
```

This is handy, but can be difficult to read if too many functions are nested, as
R evaluates the expression from the inside out (in this case, filtering, then selecting).

The last option, *pipes*, are a recent addition to R. Pipes let you take
the output of one function and send it directly to the next, which is useful
when you need to do many things to the same dataset.

Pipes in R look like `%>%` (made available via the **`magrittr`**
package) or `|>` (through base R). If you use RStudio, you can type
the pipe with <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you
have a PC or <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you
have a Mac.

In the above code, we use the pipe to send the `rna` dataset first
through `filter()` to keep rows where `sex` is Male, then through
`select()` to keep only the `gene`, `sample`, `tissue`, and
`expression`columns.

The pipe `%>%` takes the object on its left and passes it directly as
the first argument to the function on its right, we don't need to
explicitly include the data frame as an argument to the `filter()` and
`select()` functions any more.

```{r, purl=TRUE}
rna %>%
  filter(sex == "Male") %>%
  select(gene, sample, tissue, expression)
```

Some may find it helpful to read the pipe like the word "then". For instance,
in the above example, we took the data frame `rna`, *then* we `filter`ed
for rows with `sex == "Male"`, *then* we `select`ed columns `gene`, `sample`,
`tissue`, and `expression`.

The **`dplyr`** functions by themselves are somewhat simple, but by
combining them into linear workflows with the pipe, we can accomplish
more complex manipulations of data frames.

If we want to create a new object with this smaller version of the data, we
can assign it a new name:

```{r, purl=TRUE}
rna3 <- rna %>%
  filter(sex == "Male") %>%
  select(gene, sample, tissue, expression)

rna3
```

::: {.callout-note icon=false}

## Challenge:

Using pipes, subset the `rna` data to keep observations in female mice at time 0,
where the gene has an expression higher than 50000, and retain only the columns
`gene`, `sample`, `time`, `expression` and `age`.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
rna %>%
  filter(expression > 50000,
         sex == "Female",
         time == 0 ) %>%
  select(gene, sample, time, expression, age)
```



:::

## Mutate

Frequently you'll want to create new columns based on the values of existing
columns, for example to do unit conversions, or to find the ratio of values in two
columns. For this we'll use `mutate()`.

To create a new column of time in hours:

```{r, purl=TRUE}
rna %>%
  mutate(time_hours = time * 24) %>%
  select(time, time_hours)
```

You can also create a second new column based on the first new column within the same call of `mutate()`:

```{r, purl=TRUE}
rna %>%
  mutate(time_hours = time * 24,
         time_mn = time_hours * 60) %>%
  select(time, time_hours, time_mn)
```

::: {.callout-note icon=false}

## Challenge

Create a new data frame from the `rna` data that meets the following
criteria: contains only the `gene`, `chromosome_name`,
`phenotype_description`, `sample`, and `expression` columns. The expression
values should be log-transformed. This data frame must
only contain genes located on sex chromosomes, associated with a
phenotype\_description, and with a log expression higher than 5.

**Hint**: think about how the commands should be ordered to produce
this data frame!

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r, eval=TRUE, purl=TRUE}
rna %>%
  mutate(expression = log(expression)) %>%
  select(gene, chromosome_name, phenotype_description, sample, expression) %>%
  filter(chromosome_name == "X" | chromosome_name == "Y") %>%
  filter(!is.na(phenotype_description)) %>%
  filter(expression > 5)
```



:::

## Split-apply-combine data analysis

Many data analysis tasks can be approached using the
*split-apply-combine* paradigm: split the data into groups, apply some
analysis to each group, and then combine the results. **`dplyr`**
makes this very easy through the use of the `group_by()` function.

```{r}
rna %>%
  group_by(gene)
```

The `group_by()` function doesn't perform any data processing, it
groups the data into subsets: in the example above, our initial
`tibble` of `r nrow(rna)` observations is split into
`r length(unique(rna$gene))` groups based on the `gene` variable.

We could similarly decide to group the tibble by the samples:

```{r}
rna %>%
  group_by(sample)
```

Here our initial `tibble` of `r nrow(rna)` observations is split into
`r length(unique(rna$sample))` groups based on the `sample` variable.

Once the data has been grouped, subsequent operations will be
applied on each group independently.

### The `summarise()` function

`group_by()` is often used together with `summarise()`, which
collapses each group into a single-row summary of that group.

`group_by()` takes as arguments the column names that contain the
**categorical** variables for which you want to calculate the summary
statistics. So to compute the mean `expression` by gene:

```{r}
rna %>%
  group_by(gene) %>%
  summarise(mean_expression = mean(expression))
```

We could also want to calculate the mean expression levels of all genes in each sample:

```{r}
rna %>%
  group_by(sample) %>%
  summarise(mean_expression = mean(expression))
```

But we can can also group by multiple columns:

```{r}
rna %>%
  group_by(gene, infection, time) %>%
  summarise(mean_expression = mean(expression))
```

Once the data is grouped, you can also summarise multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add a
column indicating the median `expression` by gene and by condition:

```{r, purl=TRUE}
rna %>%
  group_by(gene, infection, time) %>%
  summarise(mean_expression = mean(expression),
            median_expression = median(expression))
```

::: {.callout-note icon=false}

## Challenge

Calculate the mean expression level of gene "Dok3" by timepoints.

:::


::: {.callout-tip icon=false collapse=true}

## Solution

```{r, purl=TRUE}
rna %>%
  filter(gene == "Dok3") %>%
  group_by(time) %>%
  summarise(mean = mean(expression))
```

:::

### Counting

When working with data, we often want to know the number of observations found
for each factor or combination of factors. For this task, **`dplyr`** provides
`count()`. For example, if we wanted to count the number of rows of data for
each infected and non-infected samples, we would do:

```{r, purl=TRUE}
rna %>%
    count(infection)
```

The `count()` function is shorthand for something we've already seen: grouping by a variable, and summarising it by counting the number of observations in that group. In other words, `rna %>% count(infection)` is equivalent to:

```{r, purl=TRUE}
rna %>%
    group_by(infection) %>%
    summarise(n = n())
```

The previous example shows the use of `count()` to count the number of rows/observations
for *one* factor (i.e., `infection`).
If we wanted to count a *combination of factors*, such as `infection` and `time`,
we would specify the first and the second factor as the arguments of `count()`:

```{r, purl=TRUE}
rna %>%
    count(infection, time)
```

which is equivalent to this:

```{r, purl=TRUE}
rna %>%
  group_by(infection, time) %>%
  summarise(n = n())
```

It is sometimes useful to sort the result to facilitate the comparisons.
We can use `arrange()` to sort the table.
For instance, we might want to arrange the table above by time:

```{r, purl=TRUE}
rna %>%
  count(infection, time) %>%
  arrange(time)
```

or by counts:

```{r, purl=TRUE}
rna %>%
  count(infection, time) %>%
  arrange(n)
```

To sort in descending order, we need to add the `desc()` function:

```{r, purl=TRUE}
rna %>%
  count(infection, time) %>%
  arrange(desc(n))
```

::: {.callout-note icon=false}

## Challenge

1. How many genes were analysed in each sample?
2. Use `group_by()` and `summarise()` to evaluate the sequencing depth (the sum of all counts) in each sample. Which sample has the highest sequencing depth?
3. Pick one sample and evaluate the number of genes by biotype.
4. Identify genes associated with the "abnormal DNA methylation" phenotype description, and calculate their mean expression (in log) at time 0, time 4 and time 8.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
## 1.
rna %>%
  count(sample)
## 2.
rna %>%
  group_by(sample) %>%
  summarise(seq_depth = sum(expression)) %>%
  arrange(desc(seq_depth))
## 3.
rna %>%
  filter(sample == "GSM2545336") %>%
  group_by(gene_biotype) %>%
  count(gene_biotype) %>%
  arrange(desc(n))
## 4.
rna %>%
  filter(phenotype_description == "abnormal DNA methylation") %>%
  group_by(gene, time) %>%
  summarise(mean_expression = mean(log(expression))) %>%
  arrange()
```


:::

## Reshaping data

In the `rna` tibble, the rows contain expression values (the unit) that are
associated with a combination of 2 other variables: `gene` and `sample`.

All the other columns correspond to variables describing either
the sample (organism, age, sex, ...) or the gene (gene\_biotype, ENTREZ\_ID, product, ...).
The variables that don't change with genes or with samples will have the same value in all the rows.

```{r}
rna %>%
  arrange(gene)
```

This structure is called a `long-format`, as one column contains all the values,
and other column(s) list(s) the context of the value.

In certain cases, the `long-format` is not really "human-readable", and another format,
a `wide-format` is preferred, as a more compact way of representing the data.
This is typically the case with gene expression values that scientists are used to
look as matrices, were rows represent genes and columns represent samples.

In this format, it would therefore become straightforward
to explore the relationship between the gene expression levels within, and
between, the samples.

```{r, echo=FALSE}
rna %>%
  select(gene, sample, expression) %>%
  pivot_wider(names_from = sample,
              values_from = expression)
```

To convert the gene expression values from `rna` into a wide-format,
we need to create a new table where the values of the `sample` column would
become the names of column variables.

The key point here is that we are still following
a tidy data structure, but we have **reshaped** the data according to
the observations of interest: expression levels per gene instead
of recording them per gene and per sample.

The opposite transformation would be to transform column names into
values of a new variable.

We can do both these of transformations with two `tidyr` functions,
`pivot_longer()` and `pivot_wider()` (see
[here](https://tidyr.tidyverse.org/dev/articles/pivot.html) for
details).

### Pivoting the data into a wider format

Let's select the first 3 columns of `rna` and use `pivot_wider()`
to transform the data into a wide-format.

```{r, purl=TRUE}
rna_exp <- rna %>%
  select(gene, sample, expression)
rna_exp
```

`pivot_wider` takes three main arguments:

1. the data to be transformed;
2. the `names_from` : the column whose values will become new column
  names;
3. the `values_from`: the column whose values will fill the new
  columns.

```{r, fig.cap="Wide pivot of the `rna` data.", echo=FALSE, message=FALSE}
knitr::include_graphics("../../img/pivot_wider.png")
```

```{r, purl=TRUE}
rna_wide <- rna_exp %>%
  pivot_wider(names_from = sample,
              values_from = expression)
rna_wide
```

Note that by default, the `pivot_wider()` function will add `NA` for missing values.

Let's imagine that for some reason, we had some missing expression values for some
genes in certain samples. In the following fictive example, the gene Cyp2d22 has only
one expression value, in GSM2545338 sample.

```{r, purl=TRUE, echo=FALSE}
rna_with_missing_values <- rna %>%
  select(gene, sample, expression) %>%
  filter(gene %in% c("Asl", "Apod", "Cyp2d22")) %>%
  filter(sample %in% c("GSM2545336", "GSM2545337", "GSM2545338")) %>%
  arrange(sample) %>%
  filter(!(gene == "Cyp2d22" & sample != "GSM2545338"))
```

```{r, purl=TRUE}
rna_with_missing_values
```

By default, the `pivot_wider()` function will add `NA` for missing
values. This can be parameterised with the `values_fill` argument of
the `pivot_wider()` function.

```{r, purl=TRUE}
rna_with_missing_values %>%
  pivot_wider(names_from = sample,
              values_from = expression)

rna_with_missing_values %>%
  pivot_wider(names_from = sample,
              values_from = expression,
              values_fill = 0)
```

### Pivoting data into a longer format

In the opposite situation we are using the column names and turning them into
a pair of new variables. One variable represents the column names as
values, and the other variable contains the values previously
associated with the column names.

`pivot_longer()` takes four main arguments:

1. the data to be transformed;
2. the `names_to`: the new column name we wish to create and populate with the
  current column names;
3. the `values_to`: the new column name we wish to create and populate with
  current values;
4. the names of the columns to be used to populate the `names_to` and
  `values_to` variables (or to drop).

```{r, fig.cap="Long pivot of the `rna` data.", echo=FALSE, message=FALSE}
knitr::include_graphics("../../img/pivot_longer.png")
```

To recreate `rna_long` from `rna_wide` we would create a key
called `sample` and value called `expression` and use all columns
except `gene` for the key variable. Here we drop `gene` column
with a minus sign.

Notice how the new variable names are to be quoted here.

```{r}
rna_long <- rna_wide %>%
    pivot_longer(names_to = "sample",
                 values_to = "expression",
                 -gene)
rna_long
```

We could also have used a specification for what columns to
include. This can be useful if you have a large number of identifying
columns, and it's easier to specify what to gather than what to leave
alone. Here the `starts_with()` function can help to retrieve sample
names without having to list them all!
Another possibility would be to use the `:` operator!

```{r}
rna_wide %>%
    pivot_longer(names_to = "sample",
                 values_to = "expression",
                 cols = starts_with("GSM"))
rna_wide %>%
    pivot_longer(names_to = "sample",
                 values_to = "expression",
                 GSM2545336:GSM2545380)
```

Note that if we had missing values in the wide-format, the `NA` would be
included in the new long format.

Remember our previous fictive tibble containing missing values:

```{r}
rna_with_missing_values

wide_with_NA <- rna_with_missing_values %>%
  pivot_wider(names_from = sample,
              values_from = expression)
wide_with_NA

wide_with_NA %>%
    pivot_longer(names_to = "sample",
                 values_to = "expression",
                 -gene)
```

Pivoting to wider and longer formats can be a useful way to balance out a dataset
so every replicate has the same composition.

::: {.callout-note icon=false}

## Question

Starting from the rna table, use the `pivot_wider()` function to create
a wide-format table giving the gene expression levels in each mouse.
Then use the `pivot_longer()` function to restore a long-format table.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r, answer=TRUE, purl=TRUE}
rna1 <- rna %>%
select(gene, mouse, expression) %>%
pivot_wider(names_from = mouse, values_from = expression)
rna1

rna1 %>%
pivot_longer(names_to = "mouse_id", values_to = "counts", -gene)
```

:::

::: {.callout-note icon=false}

## Question

Subset genes located on X and Y chromosomes from the `rna` data frame and
spread the data frame with `sex` as columns, `chromosome_name` as
rows, and the mean expression of genes located in each chromosome as the values,
as in the following tibble:

```{r, echo=FALSE, message=FALSE}
knitr::include_graphics("../../img/Exercise_pivot_W.png")
```

You will need to summarise before reshaping!

:::

::: {.callout-tip icon=false collapse=true}

## Solution

Let's first calculate the mean expression level of X and Y linked genes from
male and female samples...

```{r}
 rna %>%
  filter(chromosome_name == "Y" | chromosome_name == "X") %>%
  group_by(sex, chromosome_name) %>%
  summarise(mean = mean(expression))
```

And pivot the table to wide format

```{r, answer=TRUE, purl=TRUE}
rna_1 <- rna %>%
  filter(chromosome_name == "Y" | chromosome_name == "X") %>%
  group_by(sex, chromosome_name) %>%
  summarise(mean = mean(expression)) %>%
  pivot_wider(names_from = sex,
              values_from = mean)

rna_1
```

Now take that data frame and transform it with `pivot_longer()` so
each row is a unique `chromosome_name` by `gender` combination.

```{r, answer=TRUE, purl=TRUE}
rna_1 %>%
  pivot_longer(names_to = "gender",
               values_to = "mean",
               -chromosome_name)

```

:::

::: {.callout-note icon=false}

## Question

Use the `rna` dataset to create an expression matrix where each row
represents the mean expression levels of genes and columns represent
the different timepoints.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

Let's first calculate the mean expression by gene and by time

```{r}
rna %>%
  group_by(gene, time) %>%
  summarise(mean_exp = mean(expression))
```

before using the pivot\_wider() function

```{r}
rna_time <- rna %>%
  group_by(gene, time) %>%
  summarise(mean_exp = mean(expression)) %>%
  pivot_wider(names_from = time,
              values_from = mean_exp)
rna_time
```

Notice that this generates a tibble with some column names starting by a number.
If we wanted to select the column corresponding to the timepoints,
we could not use the column names directly... What happens when we select the column 4?

```{r}
rna %>%
  group_by(gene, time) %>%
  summarise(mean_exp = mean(expression)) %>%
  pivot_wider(names_from = time,
              values_from = mean_exp) %>%
  select(gene, 4)
```

To select the timepoint 4, we would have to quote the column name, with backticks "\`"

```{r}
rna %>%
  group_by(gene, time) %>%
  summarise(mean_exp = mean(expression)) %>%
  pivot_wider(names_from = time,
              values_from = mean_exp) %>%
  select(gene, `4`)
```

Another possibility would be to rename the column,
choosing a name that doesn't start by a number :

```{r}
rna %>%
  group_by(gene, time) %>%
  summarise(mean_exp = mean(expression)) %>%
  pivot_wider(names_from = time,
              values_from = mean_exp) %>%
  rename("time0" = `0`, "time4" = `4`, "time8" = `8`) %>%
  select(gene, time4)
```


:::

::: {.callout-note icon=false}

## Question

Use the previous data frame containing mean expression levels per timepoint and create
a new column containing fold-changes between timepoint 8 and timepoint 0, and fold-changes
between timepoint 8 and timepoint 4.
Convert this table into a long-format table gathering the fold-changes calculated.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

Starting from the rna\_time tibble:

```{r}
rna_time
```

Calculate fold-changes:

```{r}
rna_time %>%
  mutate(time_8_vs_0 = `8` / `0`, time_8_vs_4 = `8` / `4`)
```

And use the pivot\_longer() function:

```{r}
rna_time %>%
  mutate(time_8_vs_0 = `8` / `0`, time_8_vs_4 = `8` / `4`) %>%
  pivot_longer(names_to = "comparisons",
               values_to = "Fold_changes",
               time_8_vs_0:time_8_vs_4)
```

:::

## Joining tables

In many real life situations, data are spread across multiple tables.
Usually this occurs because different types of information are
collected from different sources.

It may be desirable for some analyses to combine data from two or more
tables into a single data frame based on a column that would be common
to all the tables.

The `dplyr` package provides a set of join functions for combining two
data frames based on matches within specified columns. Here, we
provide a short introduction to joins. The
[Data Transformation Cheat
Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf)
also provides a short overview on table joins.

We are going to illustrate join using a small table, `rna_mini` that
we will create by subsetting the original `rna` table, keeping only 3
columns and 10 lines.

```{r}
rna_mini <- rna %>%
   select(gene, sample, expression) %>%
   head(10)
rna_mini
```

The second table, `annot1`, contains 2 columns, gene and
gene\_description.

```{r, message=FALSE}
annot1 <- read_csv(file = "data/annot1.csv")
annot1
```

We now want to join these two tables into a single one containing all
variables using the `full_join()` function from the `dplyr` package. The
function will automatically find the common variable to match columns
from the first and second table.  In this case, `gene` is the common
variable. Such variables are called keys. Keys are used to match
observations across different tables.

```{r}
full_join(rna_mini, annot1)
```

In real life, gene annotations are sometimes labelled differently.

The `annot2` table is exactly the same than `annot1` except that the
variable containing gene names is labelled differently. 

```{r, message=FALSE}
annot2 <- read_csv(file = "data/annot2.csv")
```

In case none of the variable names match, we can set manually the
variables to use for the matching.  These variables can be set using
the `by` argument, as shown below with `rna_mini` and `annot2` tables.

```{r}
full_join(rna_mini, annot2, by = c("gene" = "external_gene_name"))
```

As can be seen above, the variable name of the first table is retained
in the joined one.

::: {.callout-note icon=false}

## Challenge:

Load in the file `annot3.csv`. Using the `full_join()`
function, join tables `rna_mini` and `annot3`. What has happened for
genes *Klk6*, *mt-Tf*, *mt-Rnr1*, *mt-Tv*, *mt-Rnr2*, and *mt-Tl1* ?

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r, message=FALSE}
annot3 <- read_csv("data/annot3.csv")
full_join(rna_mini, annot3)
```

Genes *Klk6* is only present in `rna_mini`, while genes *mt-Tf*, *mt-Rnr1*, *mt-Tv*,
*mt-Rnr2*, and *mt-Tl1* are only present in `annot3` table. Their respective values for the
variables of the table have been encoded as missing.

:::

## Exporting data

Now that you have learned how to use `dplyr` to extract information from
or summarise your raw data, you may want to export these new data sets to share
them with your collaborators or for archival.

Similar to the `read_csv()` function used for reading CSV files into R, there is
a `write_csv()` function that generates CSV files from data frames.

Before using `write_csv()`, we are going to create a new folder, `data_output`,
in our working directory that will store this generated dataset. We don't want
to write generated datasets in the same directory as our raw data.
It's good practice to keep them separate. The `data` folder should only contain
the raw, unaltered data, and should be left alone to make sure we don't delete
or modify it. In contrast, our script will generate the contents of the `data_output`
directory, so even if the files it contains are deleted, we can always
re-generate them.

Let's use `write_csv()` to save the rna\_wide table that we have created previously.

```{r, purl=TRUE, eval=FALSE}
write_csv(rna_wide, file = "data_output/rna_wide.csv")
```


------------------------------------------------------------------------

*The materials in this lesson have been adapted from work created by the (HBC)\](http://bioinformatics.sph.harvard.edu/) and Data Carpentry (http://datacarpentry.org/), as well as materials created by Laurent Gatto, Charlotte Soneson, Jenny Drnevich, Robert Castelo, and Kevin Rue-Albert. These are open access materials distributed under the terms of the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/) (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.*